[
  {
    "objectID": "portfolio.html#featured-projects",
    "href": "portfolio.html#featured-projects",
    "title": "My Portfolio",
    "section": "Featured projects",
    "text": "Featured projects\n\n\n\n\nProject 1 ‚Äî A cursory look into health expenditure in Canada 2025\nGoal: Visualizing Canadian expenditure on hospitals, physicians, medications, public health, administration, COVID-1 response and other professionals by provincial, public and private sector.\nNotes:\n\nFrom National Health Expenditure Trends found on CIHI.\n\nView output ‚Üí\n\n\n\n\n\n\nProject 2 ‚Äî Student lifestyle factors and its influence on school performance: A Kaggle dataset.\nGoal: To provide an exploratory analysis of how student lifestyles affect school performance in Portugal.\nNotes:\n\nOriginal dataset can be found on Kaggle.\n\nView results‚Üí\n\n\n\n\n\n\nProject 3 ‚Äî Tuning a machine learning algorithm on Cleveland dataset\nGoal: Visualize optimal hyperparameter values for a random forest model.\nNotes:\n\nThe original dataset can be found at UC Irvine‚Äôs Machine Learning Repository.\n\nView results‚Üí\n\n\n\n\n\n\nProject 4 ‚Äî Diagnostic performance using generative art\nSummary: A reproduction of an analysis inspired by generative art.\n\nNotes: I have found it useful to borrow tools from artists to help describe complex data.\nView output ‚Üí\n\n\n\n\n\n\nProject 5 ‚Äî Overview of the tidymodels R-package and sample code\nSummary: The tidymodels package is designed to optimize the prevention of data leakage when training and testing machine learning models. I outline the package here.\n\nView output‚Üí"
  },
  {
    "objectID": "portfolio.html#get-in-touch",
    "href": "portfolio.html#get-in-touch",
    "title": "My Portfolio",
    "section": "Get in touch",
    "text": "Get in touch\n\n\n\n\n\n\nIf you‚Äôre curious about a project, want a quick walkthrough, or have a dataset you‚Äôd like to make more tangible, feel free to reach out.\n\nEmail: zbolabs@gmail.com"
  },
  {
    "objectID": "about.html#hi-im-ben",
    "href": "about.html#hi-im-ben",
    "title": "About Me",
    "section": "Hi ‚Äî I‚Äôm Ben",
    "text": "Hi ‚Äî I‚Äôm Ben\nI‚Äôm a biostatistician, epidemiologist, and data scientist who focuses on making complex data understandable, honest, and useful ‚Äî especially for people who don‚Äôt live in statistics every day.\nI work at the intersection of health, science, and decision-making, where the goal isn‚Äôt just a model that runs, but insight someone can actually use."
  },
  {
    "objectID": "about.html#how-i-think-about-data",
    "href": "about.html#how-i-think-about-data",
    "title": "About Me",
    "section": "How I think about data",
    "text": "How I think about data\nI treat data work like a workshop:\n\nstart by understanding the material\n\ntake messy things apart carefully\n\nrebuild them into something simpler and stronger\n\nexplain the result in plain language\n\nThat means transparent assumptions, clear visuals, and an emphasis on what the results mean ‚Äî not just how clever the method was."
  },
  {
    "objectID": "about.html#credentials-at-a-glance",
    "href": "about.html#credentials-at-a-glance",
    "title": "About Me",
    "section": "Credentials (at a glance)",
    "text": "Credentials (at a glance)\n\n\nTraining - PhD ‚Äî Epidemiology\n- MSc ‚Äî Applied Mathematics & Statistics\n- Doctor of Veterinary Medicine (DVM)\nCore methods - Statistical modeling & inference\n- Machine learning (applied, not buzzword-driven)\n- Study design & evaluation\n\nDomains - Public & population health\n- Clinical & real-world evidence\n- Diagnostics & infection control\nTools - R, Python, SQL\n- Quarto, Shiny, GitHub\n- Reproducible research workflows"
  },
  {
    "objectID": "about.html#what-youll-see-on-this-site",
    "href": "about.html#what-youll-see-on-this-site",
    "title": "About Me",
    "section": "What you‚Äôll see on this site",
    "text": "What you‚Äôll see on this site\n\nCase studies showing how I approach real problems\n\nExplain-it-clearly posts for tricky concepts\n\nTools & templates you can reuse\n\nOccasional experiments and side projects\n\nEverything here is meant to be practical, readable, and honest."
  },
  {
    "objectID": "about.html#get-in-touch",
    "href": "about.html#get-in-touch",
    "title": "About Me",
    "section": "Get in touch",
    "text": "Get in touch\nIf something here resonates, or you‚Äôd like a walkthrough of a project:\n\nüìß Email: your@email.com\n\nüíª GitHub: https://github.com/YOURNAME\n\nüîó LinkedIn: https://linkedin.com/in/YOURNAME"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome To My Lab",
    "section": "",
    "text": "I make data science simple, tangible, and honest.\nThis site is built like a small online laboratory: - the Portfolio is for snapshots of finished work: clean and polished\n- the Lab is for work in progress‚Äîdrafts, experiments, and ideas taking shape"
  },
  {
    "objectID": "index.html#where-would-you-like-to-start",
    "href": "index.html#where-would-you-like-to-start",
    "title": "Welcome To My Lab",
    "section": "Where would you like to start?",
    "text": "Where would you like to start?\n\n\n\n\n‚úÖ Portfolio\nSnapshots of finished projects.\n\nCase studies\nPractical visuals and plain-language conclusions\n\nEnter the Portfolio ‚Üí\n\n\n\n\n\n\nüß™ Lab\nActive builds and prototypes.\n\nExperiments\nOpen questions and next steps\n\nStep into the Lab ‚Üí"
  },
  {
    "objectID": "index.html#what-i-aim-for",
    "href": "index.html#what-i-aim-for",
    "title": "Welcome To My Lab",
    "section": "What I aim for",
    "text": "What I aim for\n\n\n\nClarity\nIf it can‚Äôt be explained simply, it isn‚Äôt done yet.\n\n\n\nIntegrity\nTransparent assumptions, honest uncertainty, and evaluations that don‚Äôt oversell.\n\n\n\n\n\nImpactful\nOutput framed for clarity and the potential for decision-readiness (assuming data is valid).\n\n\n:::"
  },
  {
    "objectID": "index.html#say-hello",
    "href": "index.html#say-hello",
    "title": "Welcome To My Lab",
    "section": "Say hello",
    "text": "Say hello\n\n\n\n\n\n\nIf you‚Äôd like to collaborate, chat about a project, or ask a question:\n\nEmail: zbolabs@gmail.com"
  },
  {
    "objectID": "student_lifestyle_data_kaggle.html",
    "href": "student_lifestyle_data_kaggle.html",
    "title": "Lifestyle factors and their impact on students - Analysis of Kaggle dataset",
    "section": "",
    "text": "This practice analysis utilized data on lifestyle factors and student performance found on Kaggle.1\n\nThis dataset provides a detailed view of student lifestyle patterns and their correlation with academic performance, represented by GPA. It contains 2,000 records of students‚Äô daily habits across study, extracurriculars, sleep, socializing, and physical activities. Each student‚Äôs stress level is derived based on study and sleep hours, offering insights into how lifestyle factors may impact academic outcomes.  This dataset, contains data from 2,000 students of university collected via a Google Form survey. It includes information on study hours, extracurricular activities, sleep, socializing, physical activity, stress levels, and CGPA. The data covers an academic year from August 2023 to May 2024 and reflects student of Lisboa. This dataset can help analyze the impact of daily habits on academic performance and student well-being.\n\nThe purpose of this analysis was to practice statistical methods through the investigation of potential associations between academic performance (grades) and lifestyle factors. This analysis was financially and resource constrained and was, thus, uninformed by subject matter expertise. Findings were statistical in nature only. Any discussion was purely speculative and should not be taken into consideration without consulting appropriate experts in the field."
  },
  {
    "objectID": "student_lifestyle_data_kaggle.html#footnotes",
    "href": "student_lifestyle_data_kaggle.html#footnotes",
    "title": "Lifestyle factors and their impact on students - Analysis of Kaggle dataset",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://www.kaggle.com/datasets/charlottebennett1234/lifestyle-factors-and-their-impact-on-students/data‚Ü©Ô∏é"
  },
  {
    "objectID": "biomarker_slopes.html",
    "href": "biomarker_slopes.html",
    "title": "Investigation of the diagnostic performance of a biomarker (simulated reproduction)",
    "section": "",
    "text": "Introduction\nThe following is a reproduction of a set of visualizations I produced for a study and subsequent publication. These were particularly helpful when collaborating with our clinical team whose expertise were in non-statistical fields. It helped us achieve and maintain alignment, helping us efficiently achieve our goals.\nWe were investigating a biomarker and its behavior over time in healthy (controls) and diseased (exposed) subjects. The hypothesis was that biomarker values that increased over time indicated disease, while biomarkers that stayed constant through time indicated health. Furthermore, in order for clinicians to adopt this biomarker, the diagnostic performance of this biomarker needed to be highly accurate with near-zero misclassifications. The following visualizations were produced from a simplified simulation of the data.\nThe progression of each patient‚Äôs biomarker progression through time is presented below. A visual inspection shows us that increases in biomarker values tended to occur more often with sick than with healthy patients. We can also see that the data is unbalanced.\n\n\n\n\n\n\n\n\n\n\n\nBoxplots of slopes help us understand the diagnostic performance of the data\nIn order to diagnose disease, we must see an increase in biomarker values over time. Using linear regression, we can calculate the slope of each patient‚Äôs biomarker values over time. We can compare the slopes of healthy patients against the slopes of sick patients.\nIn the plot below, we can see that the biomarker slopes of sick patients tends to be higher than those of healthy patients. However, with regards to diagnostic performance, there was still a chance of misclassifications that was unacceptable to our clinicians.\n\n\n\n\n\n\n\n\n\n\n\nRadial plots help us assess diagnostic performance with data completeness in mind.\nIn order to better understand the cause of this, I created another visualization tool, called radial plots. For each patient, lines were generated using the slope calculated from linear regression originating from a common intercept.\nThe radial plot below illustrates each patient‚Äôs slope of biomarker values. The dotted red and blue lines indicated patients correctly classified as sick and healthy, respectively. The solid blue line indicated a healthy patient misclassified as sick. The solid red line indicated sick patients misclassified as healthy. One thing to note is that misclassified patients had shorter follow-up periods compared to correctly classified patients. This information allowed our clincial team to look more closely into the cause of shorter follow-up periods providing explanations for misclassifications and helping us investigate the diagnostic performance of this biomarker more thoroughly."
  },
  {
    "objectID": "rf_tuning_cleveland.html",
    "href": "rf_tuning_cleveland.html",
    "title": "Grid search accuracy results for random forest hyperparameters fit on Cleveland dataset",
    "section": "",
    "text": "The figure illustrates accuracies for differing values of the major hyperparameters (through grid search) of the random forest method: number of trees and number of variables to sample."
  },
  {
    "objectID": "lab.html",
    "href": "lab.html",
    "title": "My Lab",
    "section": "",
    "text": "NoteWelcome to My Lab\n\n\n\nThe Portfolio is for finished, polished projects.\nThe Lab is where I work in public: prototypes, drafts, and experiments‚Äîshared early so the thinking is visible."
  },
  {
    "objectID": "lab.html#now-brewing",
    "href": "lab.html#now-brewing",
    "title": "My Lab",
    "section": "Now brewing ‚òïÔ∏è",
    "text": "Now brewing ‚òïÔ∏è\n\n\n\n\nProject: Cold weather\nStatus: Concept ‚Üí Data access\nWhy I‚Äôm doing it: .\nCurrent focus:\nNext steps:\nLinks -\n\n\n\n\n\n\nProject:\nStatus:\nWhy I‚Äôm doing it:\nWhat I‚Äôve learned so far\nRisks / unknowns\nLinks -"
  },
  {
    "objectID": "lab.html#experiment-log",
    "href": "lab.html#experiment-log",
    "title": "My Lab",
    "section": "Experiment log",
    "text": "Experiment log\nA running list of smaller trials and ideas.\n\n\n\nRecent experiments\n\n2025-12-29: Tested an alternative evaluation metric for (project).\n2025-12-22: Built a first-pass pipeline for (dataset).\n2025-12-15: Explored a visualization style for (concept).\n\n\n\n\nBacklog\n\nCalibration check + plain-language explainer\n‚ÄúMinimum viable dashboard‚Äù template\nReproducible data cleaning checklist"
  },
  {
    "objectID": "lab.html#notes-drafts-living-documents",
    "href": "lab.html#notes-drafts-living-documents",
    "title": "My Lab",
    "section": "Notes & drafts (living documents)",
    "text": "Notes & drafts (living documents)\nUse these as your ‚Äúlab notebook‚Äù pages.\n\nLab Notes 1\nLab Notes 2\nSketches & snippets"
  },
  {
    "objectID": "lab.html#collaboration-feedback",
    "href": "lab.html#collaboration-feedback",
    "title": "My Lab",
    "section": "Collaboration / feedback",
    "text": "Collaboration / feedback\n\n\n\n\n\n\nIf you‚Äôre curious about any of these experiments‚Äîor you notice something I should reconsider‚Äîfeedback is welcome. I‚Äôm especially interested in comments on: clarity, assumptions, and whether the output feels usable.\nEmail: zbolabs@gmail.com"
  },
  {
    "objectID": "tidymodels.html",
    "href": "tidymodels.html",
    "title": "Overview of tidymodels",
    "section": "",
    "text": "I made a summary of how to use tidymodels."
  },
  {
    "objectID": "tidymodels.html#random-forest-template",
    "href": "tidymodels.html#random-forest-template",
    "title": "Overview of tidymodels",
    "section": "Random forest template",
    "text": "Random forest template\n\n# ============================================================\n# Random Forest (tidymodels): End-to-End Workflow\n# Using `parameters()` + grid generation (no expand.grid)\n# ============================================================\n\n\n# ------------------------------------------------------------\n# Assumptions\n# ------------------------------------------------------------\n# df      : your data frame\n# outcome : factor outcome variable for classification\n# Event   : second factor level is treated as the \"event\" by yardstick\n\n# ------------------------------------------------------------\n# 1. Train / Test Split\n# ------------------------------------------------------------\nsplit &lt;- initial_split(df, prop = 0.80, strata = outcome)\ntrain &lt;- training(split)\ntest  &lt;- testing(split)\n\n# ------------------------------------------------------------\n# 2. Preprocessing Recipe\n# ------------------------------------------------------------\nrf_rec &lt;- recipe(outcome ~ ., data = train) %&gt;%\n  step_novel(all_nominal_predictors()) %&gt;%     # handle unseen levels\n  step_dummy(all_nominal_predictors()) %&gt;%     # one-hot encode factors\n  step_zv(all_predictors())                    # remove zero-variance predictors\n\n# ------------------------------------------------------------\n# 3. Random Forest Model Spec (tunable params declared via tune())\n# ------------------------------------------------------------\nrf_spec &lt;- rand_forest(\n  mtry  = tune(),\n  min_n = tune(),\n  trees = tune()\n) %&gt;%\n  set_engine(\"ranger\", importance = \"permutation\") %&gt;%\n  set_mode(\"classification\")\n\n# ------------------------------------------------------------\n# 4. Workflow\n# ------------------------------------------------------------\nrf_wf &lt;- workflow() %&gt;%\n  add_recipe(rf_rec) %&gt;%\n  add_model(rf_spec)\n\n# ------------------------------------------------------------\n# 5. Cross-Validation\n# ------------------------------------------------------------\nfolds &lt;- vfold_cv(train, v = 5, strata = outcome)\n\n# ------------------------------------------------------------\n# 6. Define parameter ranges with `parameters()`\n# ------------------------------------------------------------\n# NOTE: mtry() is data-dependent (post-recipe predictor count), so tidymodels may\n# finalize it after prepping the recipe. You can optionally set a range too.\nrf_params &lt;- parameters(\n  mtry(range = c(2, 30)),          # adjust upper bound if you expect many dummies\n  min_n(range = c(2, 40)),\n  trees(range = c(500, 2000))\n)\n\n# Build a grid from those parameter definitions\n# Option A: random grid (often better for 3+ params)\nrf_grid &lt;- grid_random(rf_params, size = 25)\n\n# Option B: regular grid (can explode quickly: levels^(#params))\n# rf_grid &lt;- grid_regular(rf_params, levels = 5)\n\n# ------------------------------------------------------------\n# 7. Hyperparameter Tuning\n# ------------------------------------------------------------\nrf_res &lt;- tune_grid(\n  rf_wf,\n  resamples = folds,\n  grid = rf_grid,\n  metrics = metric_set(roc_auc, accuracy),\n  control = control_grid(save_pred = TRUE)\n)\n\n# Examine tuning results\ncollect_metrics(rf_res)\nshow_best(rf_res, metric = \"roc_auc\", n = 10)\n\n# ------------------------------------------------------------\n# 8. Finalize Workflow with Best Parameters\n# ------------------------------------------------------------\nbest_rf &lt;- select_best(rf_res, metric = \"roc_auc\")\nrf_final_wf &lt;- finalize_workflow(rf_wf, best_rf)\n\n# ------------------------------------------------------------\n# 9. Final Test-Set Evaluation (honest performance)\n# ------------------------------------------------------------\nrf_last &lt;- last_fit(\n  rf_final_wf,\n  split = split,\n  metrics = metric_set(roc_auc, accuracy, sens, spec)\n)\n\ncollect_metrics(rf_last)\n\nrf_test_preds &lt;- collect_predictions(rf_last)\n\n# ROC curve\nrf_test_preds %&gt;%\n  roc_curve(outcome, .pred_2) %&gt;%   # replace .pred_2 with your event class column if needed\n  autoplot()\n\n# ------------------------------------------------------------\n# 10. Fit Final Model on Training Data (for interpretation)\n# ------------------------------------------------------------\nrf_fit &lt;- fit(rf_final_wf, data = train)\n\n# Variable importance (since ranger importance = \"permutation\")\nrf_engine &lt;- extract_fit_parsnip(rf_fit)$fit\nvip::vip(rf_engine, num_features = 20)\n\n# ------------------------------------------------------------\n# (Optional) Partial Dependence Plot via DALEX (workflow-safe)\n# ------------------------------------------------------------\nlibrary(DALEX)\nlibrary(DALEXtra)\n\nexplainer &lt;- explain_tidymodels(\n  rf_fit,\n  data = train,\n  y = train$outcome,\n  verbose = FALSE\n)\n\nmodel_profile(explainer, variables = \"age\") %&gt;% plot()"
  },
  {
    "objectID": "tidymodels.html#knn-template",
    "href": "tidymodels.html#knn-template",
    "title": "Overview of tidymodels",
    "section": "kNN template",
    "text": "kNN template\n\n# ============================================================\n# k-Nearest Neighbors (tidymodels): End-to-End Workflow\n# ============================================================\n\nlibrary(tidymodels)\nset.seed(123)\n\n# ------------------------------------------------------------\n# Assumptions\n# ------------------------------------------------------------\n# df        : your data frame\n# outcome   : factor outcome variable for classification\n# NOTE: k-NN is distance-based -&gt; normalization is essential.\n\n# ------------------------------------------------------------\n# 1. Train / Test Split\n# ------------------------------------------------------------\nsplit &lt;- initial_split(df, prop = 0.80, strata = outcome)\ntrain &lt;- training(split)\ntest  &lt;- testing(split)\n\n# ------------------------------------------------------------\n# 2. Preprocessing Recipe (important for k-NN!)\n# ------------------------------------------------------------\nknn_rec &lt;- recipe(outcome ~ ., data = train) %&gt;%\n  step_novel(all_nominal_predictors()) %&gt;%     # handle unseen levels\n  step_dummy(all_nominal_predictors()) %&gt;%     # one-hot encode factors\n  step_zv(all_predictors()) %&gt;%                # remove zero-variance predictors\n  step_normalize(all_numeric_predictors())     # SCALE for distances\n\n# ------------------------------------------------------------\n# 3. k-NN Model Specification (with tuning)\n# ------------------------------------------------------------\nknn_spec &lt;- nearest_neighbor(\n  neighbors   = tune(),     # k\n  dist_power  = tune(),     # 1 = Manhattan, 2 = Euclidean\n  weight_func = tune()      # how neighbors are weighted\n) %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")\n\n# ------------------------------------------------------------\n# 4. Workflow\n# ------------------------------------------------------------\nknn_wf &lt;- workflow() %&gt;%\n  add_recipe(knn_rec) %&gt;%\n  add_model(knn_spec)\n\n# ------------------------------------------------------------\n# 5. Cross-Validation\n# ------------------------------------------------------------\nfolds &lt;- vfold_cv(train, v = 5, strata = outcome)\n\n# ------------------------------------------------------------\n# 6. Parameter Ranges + Grid\n# ------------------------------------------------------------\nknn_params &lt;- parameters(\n  neighbors(range = c(3, 35)),\n  dist_power(range = c(1, 2)),\n  weight_func(values = c(\"rectangular\", \"triangular\", \"gaussian\"))\n)\n\nknn_grid &lt;- grid_regular(knn_params, levels = 5)\n# If this is too big (levels^#params), use a random grid instead:\n# knn_grid &lt;- grid_random(knn_params, size = 30)\n\n# ------------------------------------------------------------\n# 7. Hyperparameter Tuning\n# ------------------------------------------------------------\nknn_res &lt;- tune_grid(\n  knn_wf,\n  resamples = folds,\n  grid = knn_grid,\n  metrics = metric_set(roc_auc, accuracy),\n  control = control_grid(save_pred = TRUE)\n)\n\n# Examine tuning results\ncollect_metrics(knn_res)\nshow_best(knn_res, metric = \"roc_auc\", n = 10)\n\n# ------------------------------------------------------------\n# 8. Finalize Workflow with Best Parameters\n# ------------------------------------------------------------\nbest_knn &lt;- select_best(knn_res, metric = \"roc_auc\")\n\nknn_final_wf &lt;- finalize_workflow(knn_wf, best_knn)\n\n# ------------------------------------------------------------\n# 9. Final Test-Set Evaluation (honest performance)\n# ------------------------------------------------------------\nknn_last &lt;- last_fit(\n  knn_final_wf,\n  split = split,\n  metrics = metric_set(roc_auc, accuracy, sens, spec)\n)\n\ncollect_metrics(knn_last)\n\nknn_test_preds &lt;- collect_predictions(knn_last)\n\n# ROC curve\nknn_test_preds %&gt;%\n  roc_curve(outcome, .pred_2) %&gt;%   # replace .pred_2 with your event class column if needed\n  autoplot()\n\n# ------------------------------------------------------------\n# 10. Fit Final Model on Training Data (for interpretation/usage)\n# ------------------------------------------------------------\nknn_fit &lt;- fit(knn_final_wf, data = train)\n\n# (Optional) Confusion matrix at threshold 0.5\nknn_test_preds %&gt;%\n  mutate(.pred_class = factor(if_else(.pred_2 &gt;= 0.5, levels(train$outcome)[2], levels(train$outcome)[1]),\n                              levels = levels(train$outcome))) %&gt;%\n  conf_mat(outcome, .pred_class)"
  },
  {
    "objectID": "tidymodels.html#neural-networks",
    "href": "tidymodels.html#neural-networks",
    "title": "Overview of tidymodels",
    "section": "Neural networks",
    "text": "Neural networks\n\n# ============================================================\n# Neural Net (tidymodels): End-to-End Workflow\n# Using `mlp()` + `parameters()` + tuning + test evaluation\n# Engine: nnet (lightweight, good for portfolios)\n# ============================================================\n\nlibrary(tidymodels)\nlibrary(dials)\nlibrary(rlang)\n\nset.seed(123)\n\n# ------------------------------------------------------------\n# Assumptions\n# ------------------------------------------------------------\n# df      : your data frame\n# outcome : factor outcome variable for classification\n# NOTE: Neural nets are scale-sensitive -&gt; normalization is essential.\n\n# ------------------------------------------------------------\n# 1. Train / Test Split\n# ------------------------------------------------------------\nsplit &lt;- initial_split(df, prop = 0.80, strata = outcome)\ntrain &lt;- training(split)\ntest  &lt;- testing(split)\n\n# Identify the \"event\" class (tidymodels/yardstick default is the 2nd level)\nevent_level &lt;- levels(train$outcome)[2]\nprob_col &lt;- paste0(\".pred_\", event_level)\n\n# ------------------------------------------------------------\n# 2. Preprocessing Recipe (important for neural nets!)\n# ------------------------------------------------------------\nnn_rec &lt;- recipe(outcome ~ ., data = train) %&gt;%\n  step_novel(all_nominal_predictors()) %&gt;%      # handle unseen levels\n  step_dummy(all_nominal_predictors()) %&gt;%      # one-hot encode factors\n  step_zv(all_predictors()) %&gt;%                 # remove zero-variance predictors\n  step_normalize(all_numeric_predictors())      # SCALE numeric predictors\n\n# ------------------------------------------------------------\n# 3. Neural Net Model Spec (tunable params declared via tune())\n# ------------------------------------------------------------\n# `mlp()` = multilayer perceptron\n# hidden_units: size of hidden layer\n# penalty     : weight decay (regularization)\n# epochs      : training iterations\nnn_spec &lt;- mlp(\n  hidden_units = tune(),\n  penalty      = tune(),\n  epochs       = tune()\n) %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"classification\")\n\n# ------------------------------------------------------------\n# 4. Workflow\n# ------------------------------------------------------------\nnn_wf &lt;- workflow() %&gt;%\n  add_recipe(nn_rec) %&gt;%\n  add_model(nn_spec)\n\n# ------------------------------------------------------------\n# 5. Cross-Validation\n# ------------------------------------------------------------\nfolds &lt;- vfold_cv(train, v = 5, strata = outcome)\n\n# ------------------------------------------------------------\n# 6. Define parameter ranges with `parameters()`\n# ------------------------------------------------------------\n# Notes:\n# - penalty() is on a log10 scale internally (dials handles that)\n# - epochs can be modest; too high can overfit and waste time\nnn_params &lt;- parameters(\n  hidden_units(range = c(1L, 50L)),\n  penalty(range = c(-6, -1)),          # 10^-6 to 10^-1 (log10 scale)\n  epochs(range = c(50L, 400L))\n)\n\n# Random grid is usually better than regular for 3 parameters\nnn_grid &lt;- grid_random(nn_params, size = 25)\n\n# ------------------------------------------------------------\n# 7. Hyperparameter Tuning\n# ------------------------------------------------------------\nnn_res &lt;- tune_grid(\n  nn_wf,\n  resamples = folds,\n  grid = nn_grid,\n  metrics = metric_set(roc_auc, accuracy),\n  control = control_grid(save_pred = TRUE)\n)\n\n# Examine tuning results\ncollect_metrics(nn_res)\nshow_best(nn_res, metric = \"roc_auc\", n = 10)\n\n# ------------------------------------------------------------\n# 8. Finalize Workflow with Best Parameters\n# ------------------------------------------------------------\nbest_nn &lt;- select_best(nn_res, metric = \"roc_auc\")\nnn_final_wf &lt;- finalize_workflow(nn_wf, best_nn)\n\n# ------------------------------------------------------------\n# 9. Final Test-Set Evaluation (honest performance)\n# ------------------------------------------------------------\nnn_last &lt;- last_fit(\n  nn_final_wf,\n  split = split,\n  metrics = metric_set(roc_auc, accuracy, sens, spec)\n)\n\ncollect_metrics(nn_last)\n\nnn_test_preds &lt;- collect_predictions(nn_last)\n\n# ROC curve (uses the event class probability column dynamically)\nnn_test_preds %&gt;%\n  roc_curve(outcome, !!sym(prob_col)) %&gt;%\n  autoplot()\n\n# Optional: confusion matrix at 0.5 threshold (you can choose a better threshold later)\nnn_test_preds %&gt;%\n  mutate(\n    .pred_class = factor(\n      if_else(!!sym(prob_col) &gt;= 0.5, event_level, levels(train$outcome)[1]),\n      levels = levels(train$outcome)\n    )\n  ) %&gt;%\n  conf_mat(outcome, .pred_class)\n\n# ------------------------------------------------------------\n# 10. Fit Final Model on Training Data (for interpretation/usage)\n# ------------------------------------------------------------\nnn_fit &lt;- fit(nn_final_wf, data = train)\n\n# Inspect finalized model specification\nextract_spec_parsnip(nn_fit)"
  },
  {
    "objectID": "tidymodels.html#a.-objective-prediction-task-always-first",
    "href": "tidymodels.html#a.-objective-prediction-task-always-first",
    "title": "Overview of tidymodels",
    "section": "A. Objective & prediction task (always first)",
    "text": "A. Objective & prediction task (always first)\nAnswer:\nWhat problem is the model solving?\nInclude: - Outcome definition - Population - Prediction vs explanation - Unit of prediction (patient, visit, image, etc.)\nExample:\n‚ÄúWe developed a machine learning model to predict 30-day mortality among hospitalized patients using routinely collected clinical variables.‚Äù\nüö´ Don‚Äôt start with algorithms. Start with the problem."
  },
  {
    "objectID": "tidymodels.html#b.-data-study-design",
    "href": "tidymodels.html#b.-data-study-design",
    "title": "Overview of tidymodels",
    "section": "B. Data & study design",
    "text": "B. Data & study design\nAnswer:\nWhere did the data come from, and how were they used?\nInclude: - Sample size - Outcome prevalence - Train/test split - Cross-validation strategy - Any stratification or grouping\nExample:\n‚ÄúThe dataset consisted of 4,812 patients, of whom 9.6% experienced the outcome. Data were split into training (80%) and test (20%) sets, stratified by outcome. Hyperparameters were optimized using 5-fold cross-validation on the training data.‚Äù\nThis signals methodological literacy."
  },
  {
    "objectID": "tidymodels.html#c.-preprocessing-this-matters-more-than-people-think",
    "href": "tidymodels.html#c.-preprocessing-this-matters-more-than-people-think",
    "title": "Overview of tidymodels",
    "section": "C. Preprocessing (this matters more than people think)",
    "text": "C. Preprocessing (this matters more than people think)\nAnswer:\nHow was the data prepared, and was leakage avoided?\nInclude: - Handling of categorical variables - Scaling (if applicable) - Missingness handling - Zero-variance filtering - Where preprocessing occurred (inside CV!)\nExample:\n‚ÄúCategorical predictors were dummy-encoded, and predictors with zero variance were removed using a recipe-based preprocessing pipeline. All preprocessing steps were estimated within resampling folds to prevent information leakage.‚Äù\nThat last sentence is very important!"
  },
  {
    "objectID": "tidymodels.html#d.-model-specification-tuning",
    "href": "tidymodels.html#d.-model-specification-tuning",
    "title": "Overview of tidymodels",
    "section": "D. Model specification & tuning",
    "text": "D. Model specification & tuning\nAnswer:\nWhat model was fit, and how were hyperparameters chosen?\nInclude: - Algorithm - Engine/library - Tuned parameters - Optimization metric\nRandom forest example:\n‚ÄúA random forest classifier was implemented using the ranger engine. The number of candidate predictors at each split (mtry) and the minimum node size (min_n) were optimized via grid search, selecting hyperparameters that maximized cross-validated ROC AUC.‚Äù\nüö´ Don‚Äôt just say ‚Äúwe fit a random forest.‚Äù"
  },
  {
    "objectID": "tidymodels.html#e.-performance-evaluation-this-is-the-core",
    "href": "tidymodels.html#e.-performance-evaluation-this-is-the-core",
    "title": "Overview of tidymodels",
    "section": "E. Performance evaluation (this is the core)",
    "text": "E. Performance evaluation (this is the core)\nAnswer:\nHow well does the model perform on unseen data?\nAlways include: - Held-out test set results - Primary metric - Secondary metrics - Confidence intervals if possible\nExample:\n‚ÄúOn the held-out test set, the model achieved an ROC AUC of 0.82, with sensitivity of 0.74 and specificity of 0.79 at a probability threshold of 0.5.‚Äù\nOptional (but impressive): - Calibration - Decision curves - Class imbalance handling"
  },
  {
    "objectID": "tidymodels.html#f.-model-interpretation-with-restraint",
    "href": "tidymodels.html#f.-model-interpretation-with-restraint",
    "title": "Overview of tidymodels",
    "section": "F. Model interpretation (with restraint)",
    "text": "F. Model interpretation (with restraint)\nAnswer:\nHow does the model behave, and what drives predictions?\nInclude: - Variable importance (with caveats) - Partial dependence / ALE / SHAP (if used) - Clear disclaimer about causality\nExample:\n‚ÄúPermutation-based variable importance indicated that age, baseline creatinine, and oxygen saturation contributed most strongly to predictive performance. Partial dependence plots suggested nonlinear risk increases at advanced ages; however, these plots reflect model behavior rather than causal effects.‚Äù\nThis shows statistical maturity."
  },
  {
    "objectID": "tidymodels.html#g.-limitations-this-builds-trust",
    "href": "tidymodels.html#g.-limitations-this-builds-trust",
    "title": "Overview of tidymodels",
    "section": "G. Limitations (this builds trust)",
    "text": "G. Limitations (this builds trust)\nAnswer:\nWhat could go wrong or limit generalization?\nAlways include: - Observational data limitations - External validation status - Model interpretability limits\nExample:\n‚ÄúThis analysis used retrospective single-source data, and external validation was not performed. Variable importance reflects predictive contribution rather than causal relevance.‚Äù\nReviewers expect this."
  },
  {
    "objectID": "tidymodels.html#h.-practical-implications-next-steps",
    "href": "tidymodels.html#h.-practical-implications-next-steps",
    "title": "Overview of tidymodels",
    "section": "H. Practical implications / next steps",
    "text": "H. Practical implications / next steps\nAnswer:\nWhat would you do next if this mattered?\nExample:\n‚ÄúFuture work includes external validation, calibration assessment, and comparison with simpler baseline models prior to potential deployment.‚Äù\nThis signals real-world thinking."
  },
  {
    "objectID": "cahealthexpenditure2025.html",
    "href": "cahealthexpenditure2025.html",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "",
    "text": "This page presents a curated set of descriptive visualizations of healthcare spending by sector. Specific expenditures include hospitals, physicians, medications, public health, administration, COVID-19 response and other professionals."
  },
  {
    "objectID": "cahealthexpenditure2025.html#total-expenditure",
    "href": "cahealthexpenditure2025.html#total-expenditure",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "Total expenditure",
    "text": "Total expenditure"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-hospitals",
    "href": "cahealthexpenditure2025.html#on-hospitals",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On Hospitals",
    "text": "On Hospitals"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-physicians",
    "href": "cahealthexpenditure2025.html#on-physicians",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On Physicians",
    "text": "On Physicians"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-medications",
    "href": "cahealthexpenditure2025.html#on-medications",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On Medications",
    "text": "On Medications"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-public-health",
    "href": "cahealthexpenditure2025.html#on-public-health",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On Public Health",
    "text": "On Public Health"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-administration",
    "href": "cahealthexpenditure2025.html#on-administration",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On Administration",
    "text": "On Administration"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-covid-19-response-funding",
    "href": "cahealthexpenditure2025.html#on-covid-19-response-funding",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On COVID-19 Response Funding",
    "text": "On COVID-19 Response Funding"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-other-professionals",
    "href": "cahealthexpenditure2025.html#on-other-professionals",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On Other Professionals",
    "text": "On Other Professionals"
  },
  {
    "objectID": "cahealthexpenditure2025.html#total-expenditure-1",
    "href": "cahealthexpenditure2025.html#total-expenditure-1",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "Total expenditure",
    "text": "Total expenditure"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-hospitals-1",
    "href": "cahealthexpenditure2025.html#on-hospitals-1",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On Hospitals",
    "text": "On Hospitals"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-physicians-1",
    "href": "cahealthexpenditure2025.html#on-physicians-1",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On Physicians",
    "text": "On Physicians"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-medications-1",
    "href": "cahealthexpenditure2025.html#on-medications-1",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On Medications",
    "text": "On Medications"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-public-health-1",
    "href": "cahealthexpenditure2025.html#on-public-health-1",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On Public Health",
    "text": "On Public Health"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-administration-1",
    "href": "cahealthexpenditure2025.html#on-administration-1",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On Administration",
    "text": "On Administration"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-covid-19-response-funding-1",
    "href": "cahealthexpenditure2025.html#on-covid-19-response-funding-1",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On COVID-19 Response Funding",
    "text": "On COVID-19 Response Funding"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-other-professionals-1",
    "href": "cahealthexpenditure2025.html#on-other-professionals-1",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On Other Professionals",
    "text": "On Other Professionals"
  },
  {
    "objectID": "cahealthexpenditure2025.html#total-expenditure-2",
    "href": "cahealthexpenditure2025.html#total-expenditure-2",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "Total expenditure",
    "text": "Total expenditure"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-hospitals-2",
    "href": "cahealthexpenditure2025.html#on-hospitals-2",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On Hospitals",
    "text": "On Hospitals"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-physicians-2",
    "href": "cahealthexpenditure2025.html#on-physicians-2",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On Physicians",
    "text": "On Physicians"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-medications-2",
    "href": "cahealthexpenditure2025.html#on-medications-2",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On Medications",
    "text": "On Medications"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-public-health-2",
    "href": "cahealthexpenditure2025.html#on-public-health-2",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On Public Health",
    "text": "On Public Health"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-administration-2",
    "href": "cahealthexpenditure2025.html#on-administration-2",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On Administration",
    "text": "On Administration"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-covid-19-response-funding-2",
    "href": "cahealthexpenditure2025.html#on-covid-19-response-funding-2",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On COVID-19 Response Funding",
    "text": "On COVID-19 Response Funding"
  },
  {
    "objectID": "cahealthexpenditure2025.html#on-other-professionals-2",
    "href": "cahealthexpenditure2025.html#on-other-professionals-2",
    "title": "A cursory exploration of trends in National Health Expenditure in Canada from 1985 to 2025",
    "section": "On Other Professionals",
    "text": "On Other Professionals"
  },
  {
    "objectID": "tidymodels_overview.html",
    "href": "tidymodels_overview.html",
    "title": "Overview of tidymodels",
    "section": "",
    "text": "Split data in training and test set.\n\nsplit = initial_split(data, prop); train = training(split), test = testing(split)\n\nPreprocess recipe.\n\nrec = recipe(formula, data = train) %&gt;% step_novel(all_nominal_predictors()) %&gt;% step_dummy(all_nominal_predictors) %&gt;% step_zv(all_predictors()) %&gt;% step_normalize(all_continuous_predictors())\n\nSpecify model.\n\nrf_spec = rand_forest(mtry = tune(), trees = tune()) %&gt;% set_engine(engine = ‚Äúranger‚Äù) %&gt;% set_mode(‚Äúclassification)\n\nSpecify workflow.\n\nwf = workflow() %&gt;% add_recipe(rec) %&gt;% add_model(rf_spec)\n\nCross-validation/resampling scheme design.\n\nfolds = vfold_cv(data = train, v = 5, strata = outcome)\n\nTune hyperparameters.\n\nrf_parameters = parameters(mtry(range = c(3, 10)), trees(range = c(100, 5000)))\nrf_res = tune_grid(wf, grid = rf_parameters, resamples = folds, metrics = metric_set(accuracy, roc_auc))\ncollect_metrics(rf_res); show_best(rf_res, metric = ‚Äúroc_auc‚Äù, n = 10)\n\nFinalize workflow with best parameters.\n\nbest_rf = select_best(rf_res, metric = ‚Äúroc_auc‚Äù)\nrf_final_wf = finalize_workflow(rf_wf, best_rf)\n\nFinal test set evaluation.\n\nrf_last = last_fit(rf_final_wf, split = split, metrics = metric_set(roc_auc, accuracy, sens, spec))\n\nFit final model on training data (for interpretation, e.g.¬†variable importance).\n\nrf_fit = fit(rf_final_wf, data = train)\nVariable importance: rf_engine = extract_fit_parsnip(rf_fit)$fit; vip::vip(rf_engine, num_features)"
  },
  {
    "objectID": "tidymodels_overview.html#random-forest-template",
    "href": "tidymodels_overview.html#random-forest-template",
    "title": "Overview of tidymodels",
    "section": "Random forest template",
    "text": "Random forest template\n\n# ============================================================\n# Random Forest (tidymodels): End-to-End Workflow\n# Using `parameters()` + grid generation (no expand.grid)\n# ============================================================\n\n\n# ------------------------------------------------------------\n# Assumptions\n# ------------------------------------------------------------\n# df      : your data frame\n# outcome : factor outcome variable for classification\n# Event   : second factor level is treated as the \"event\" by yardstick\n\n# ------------------------------------------------------------\n# 1. Train / Test Split\n# ------------------------------------------------------------\nsplit &lt;- initial_split(df, prop = 0.80, strata = outcome)\ntrain &lt;- training(split)\ntest  &lt;- testing(split)\n\n# ------------------------------------------------------------\n# 2. Preprocessing Recipe\n# ------------------------------------------------------------\nrf_rec &lt;- recipe(outcome ~ ., data = train) %&gt;%\n  step_novel(all_nominal_predictors()) %&gt;%     # handle unseen levels\n  step_dummy(all_nominal_predictors()) %&gt;%     # one-hot encode factors\n  step_zv(all_predictors())                    # remove zero-variance predictors\n\n# ------------------------------------------------------------\n# 3. Random Forest Model Spec (tunable params declared via tune())\n# ------------------------------------------------------------\nrf_spec &lt;- rand_forest(\n  mtry  = tune(),\n  min_n = tune(),\n  trees = tune()\n) %&gt;%\n  set_engine(\"ranger\", importance = \"permutation\") %&gt;%\n  set_mode(\"classification\")\n\n# ------------------------------------------------------------\n# 4. Workflow\n# ------------------------------------------------------------\nrf_wf &lt;- workflow() %&gt;%\n  add_recipe(rf_rec) %&gt;%\n  add_model(rf_spec)\n\n# ------------------------------------------------------------\n# 5. Cross-Validation\n# ------------------------------------------------------------\nfolds &lt;- vfold_cv(train, v = 5, strata = outcome)\n\n# ------------------------------------------------------------\n# 6. Define parameter ranges with `parameters()`\n# ------------------------------------------------------------\n# NOTE: mtry() is data-dependent (post-recipe predictor count), so tidymodels may\n# finalize it after prepping the recipe. You can optionally set a range too.\nrf_params &lt;- parameters(\n  mtry(range = c(2, 30)),          # adjust upper bound if you expect many dummies\n  min_n(range = c(2, 40)),\n  trees(range = c(500, 2000))\n)\n\n# Build a grid from those parameter definitions\n# Option A: random grid (often better for 3+ params)\nrf_grid &lt;- grid_random(rf_params, size = 25)\n\n# Option B: regular grid (can explode quickly: levels^(#params))\n# rf_grid &lt;- grid_regular(rf_params, levels = 5)\n\n# ------------------------------------------------------------\n# 7. Hyperparameter Tuning\n# ------------------------------------------------------------\nrf_res &lt;- tune_grid(\n  rf_wf,\n  resamples = folds,\n  grid = rf_grid,\n  metrics = metric_set(roc_auc, accuracy),\n  control = control_grid(save_pred = TRUE)\n)\n\n# Examine tuning results\ncollect_metrics(rf_res)\nshow_best(rf_res, metric = \"roc_auc\", n = 10)\n\n# ------------------------------------------------------------\n# 8. Finalize Workflow with Best Parameters\n# ------------------------------------------------------------\nbest_rf &lt;- select_best(rf_res, metric = \"roc_auc\")\nrf_final_wf &lt;- finalize_workflow(rf_wf, best_rf)\n\n# ------------------------------------------------------------\n# 9. Final Test-Set Evaluation (honest performance)\n# ------------------------------------------------------------\nrf_last &lt;- last_fit(\n  rf_final_wf,\n  split = split,\n  metrics = metric_set(roc_auc, accuracy, sens, spec)\n)\n\ncollect_metrics(rf_last)\n\nrf_test_preds &lt;- collect_predictions(rf_last)\n\n# ROC curve\nrf_test_preds %&gt;%\n  roc_curve(outcome, .pred_2) %&gt;%   # replace .pred_2 with your event class column if needed\n  autoplot()\n\n# ------------------------------------------------------------\n# 10. Fit Final Model on Training Data (for interpretation)\n# ------------------------------------------------------------\nrf_fit &lt;- fit(rf_final_wf, data = train)\n\n# Variable importance (since ranger importance = \"permutation\")\nrf_engine &lt;- extract_fit_parsnip(rf_fit)$fit\nvip::vip(rf_engine, num_features = 20)\n\n# ------------------------------------------------------------\n# (Optional) Partial Dependence Plot via DALEX (workflow-safe)\n# ------------------------------------------------------------\nlibrary(DALEX)\nlibrary(DALEXtra)\n\nexplainer &lt;- explain_tidymodels(\n  rf_fit,\n  data = train,\n  y = train$outcome,\n  verbose = FALSE\n)\n\nmodel_profile(explainer, variables = \"age\") %&gt;% plot()"
  },
  {
    "objectID": "tidymodels_overview.html#knn-template",
    "href": "tidymodels_overview.html#knn-template",
    "title": "Overview of tidymodels",
    "section": "kNN template",
    "text": "kNN template\n\n# ============================================================\n# k-Nearest Neighbors (tidymodels): End-to-End Workflow\n# ============================================================\n\nlibrary(tidymodels)\nset.seed(123)\n\n# ------------------------------------------------------------\n# Assumptions\n# ------------------------------------------------------------\n# df        : your data frame\n# outcome   : factor outcome variable for classification\n# NOTE: k-NN is distance-based -&gt; normalization is essential.\n\n# ------------------------------------------------------------\n# 1. Train / Test Split\n# ------------------------------------------------------------\nsplit &lt;- initial_split(df, prop = 0.80, strata = outcome)\ntrain &lt;- training(split)\ntest  &lt;- testing(split)\n\n# ------------------------------------------------------------\n# 2. Preprocessing Recipe (important for k-NN!)\n# ------------------------------------------------------------\nknn_rec &lt;- recipe(outcome ~ ., data = train) %&gt;%\n  step_novel(all_nominal_predictors()) %&gt;%     # handle unseen levels\n  step_dummy(all_nominal_predictors()) %&gt;%     # one-hot encode factors\n  step_zv(all_predictors()) %&gt;%                # remove zero-variance predictors\n  step_normalize(all_numeric_predictors())     # SCALE for distances\n\n# ------------------------------------------------------------\n# 3. k-NN Model Specification (with tuning)\n# ------------------------------------------------------------\nknn_spec &lt;- nearest_neighbor(\n  neighbors   = tune(),     # k\n  dist_power  = tune(),     # 1 = Manhattan, 2 = Euclidean\n  weight_func = tune()      # how neighbors are weighted\n) %&gt;%\n  set_engine(\"kknn\") %&gt;%\n  set_mode(\"classification\")\n\n# ------------------------------------------------------------\n# 4. Workflow\n# ------------------------------------------------------------\nknn_wf &lt;- workflow() %&gt;%\n  add_recipe(knn_rec) %&gt;%\n  add_model(knn_spec)\n\n# ------------------------------------------------------------\n# 5. Cross-Validation\n# ------------------------------------------------------------\nfolds &lt;- vfold_cv(train, v = 5, strata = outcome)\n\n# ------------------------------------------------------------\n# 6. Parameter Ranges + Grid\n# ------------------------------------------------------------\nknn_params &lt;- parameters(\n  neighbors(range = c(3, 35)),\n  dist_power(range = c(1, 2)),\n  weight_func(values = c(\"rectangular\", \"triangular\", \"gaussian\"))\n)\n\nknn_grid &lt;- grid_regular(knn_params, levels = 5)\n# If this is too big (levels^#params), use a random grid instead:\n# knn_grid &lt;- grid_random(knn_params, size = 30)\n\n# ------------------------------------------------------------\n# 7. Hyperparameter Tuning\n# ------------------------------------------------------------\nknn_res &lt;- tune_grid(\n  knn_wf,\n  resamples = folds,\n  grid = knn_grid,\n  metrics = metric_set(roc_auc, accuracy),\n  control = control_grid(save_pred = TRUE)\n)\n\n# Examine tuning results\ncollect_metrics(knn_res)\nshow_best(knn_res, metric = \"roc_auc\", n = 10)\n\n# ------------------------------------------------------------\n# 8. Finalize Workflow with Best Parameters\n# ------------------------------------------------------------\nbest_knn &lt;- select_best(knn_res, metric = \"roc_auc\")\n\nknn_final_wf &lt;- finalize_workflow(knn_wf, best_knn)\n\n# ------------------------------------------------------------\n# 9. Final Test-Set Evaluation (honest performance)\n# ------------------------------------------------------------\nknn_last &lt;- last_fit(\n  knn_final_wf,\n  split = split,\n  metrics = metric_set(roc_auc, accuracy, sens, spec)\n)\n\ncollect_metrics(knn_last)\n\nknn_test_preds &lt;- collect_predictions(knn_last)\n\n# ROC curve\nknn_test_preds %&gt;%\n  roc_curve(outcome, .pred_2) %&gt;%   # replace .pred_2 with your event class column if needed\n  autoplot()\n\n# ------------------------------------------------------------\n# 10. Fit Final Model on Training Data (for interpretation/usage)\n# ------------------------------------------------------------\nknn_fit &lt;- fit(knn_final_wf, data = train)\n\n# (Optional) Confusion matrix at threshold 0.5\nknn_test_preds %&gt;%\n  mutate(.pred_class = factor(if_else(.pred_2 &gt;= 0.5, levels(train$outcome)[2], levels(train$outcome)[1]),\n                              levels = levels(train$outcome))) %&gt;%\n  conf_mat(outcome, .pred_class)"
  },
  {
    "objectID": "tidymodels_overview.html#neural-networks",
    "href": "tidymodels_overview.html#neural-networks",
    "title": "Overview of tidymodels",
    "section": "Neural networks",
    "text": "Neural networks\n\n# ============================================================\n# Neural Net (tidymodels): End-to-End Workflow\n# Using `mlp()` + `parameters()` + tuning + test evaluation\n# Engine: nnet (lightweight, good for portfolios)\n# ============================================================\n\nlibrary(tidymodels)\nlibrary(dials)\nlibrary(rlang)\n\nset.seed(123)\n\n# ------------------------------------------------------------\n# Assumptions\n# ------------------------------------------------------------\n# df      : your data frame\n# outcome : factor outcome variable for classification\n# NOTE: Neural nets are scale-sensitive -&gt; normalization is essential.\n\n# ------------------------------------------------------------\n# 1. Train / Test Split\n# ------------------------------------------------------------\nsplit &lt;- initial_split(df, prop = 0.80, strata = outcome)\ntrain &lt;- training(split)\ntest  &lt;- testing(split)\n\n# Identify the \"event\" class (tidymodels/yardstick default is the 2nd level)\nevent_level &lt;- levels(train$outcome)[2]\nprob_col &lt;- paste0(\".pred_\", event_level)\n\n# ------------------------------------------------------------\n# 2. Preprocessing Recipe (important for neural nets!)\n# ------------------------------------------------------------\nnn_rec &lt;- recipe(outcome ~ ., data = train) %&gt;%\n  step_novel(all_nominal_predictors()) %&gt;%      # handle unseen levels\n  step_dummy(all_nominal_predictors()) %&gt;%      # one-hot encode factors\n  step_zv(all_predictors()) %&gt;%                 # remove zero-variance predictors\n  step_normalize(all_numeric_predictors())      # SCALE numeric predictors\n\n# ------------------------------------------------------------\n# 3. Neural Net Model Spec (tunable params declared via tune())\n# ------------------------------------------------------------\n# `mlp()` = multilayer perceptron\n# hidden_units: size of hidden layer\n# penalty     : weight decay (regularization)\n# epochs      : training iterations\nnn_spec &lt;- mlp(\n  hidden_units = tune(),\n  penalty      = tune(),\n  epochs       = tune()\n) %&gt;%\n  set_engine(\"nnet\") %&gt;%\n  set_mode(\"classification\")\n\n# ------------------------------------------------------------\n# 4. Workflow\n# ------------------------------------------------------------\nnn_wf &lt;- workflow() %&gt;%\n  add_recipe(nn_rec) %&gt;%\n  add_model(nn_spec)\n\n# ------------------------------------------------------------\n# 5. Cross-Validation\n# ------------------------------------------------------------\nfolds &lt;- vfold_cv(train, v = 5, strata = outcome)\n\n# ------------------------------------------------------------\n# 6. Define parameter ranges with `parameters()`\n# ------------------------------------------------------------\n# Notes:\n# - penalty() is on a log10 scale internally (dials handles that)\n# - epochs can be modest; too high can overfit and waste time\nnn_params &lt;- parameters(\n  hidden_units(range = c(1L, 50L)),\n  penalty(range = c(-6, -1)),          # 10^-6 to 10^-1 (log10 scale)\n  epochs(range = c(50L, 400L))\n)\n\n# Random grid is usually better than regular for 3 parameters\nnn_grid &lt;- grid_random(nn_params, size = 25)\n\n# ------------------------------------------------------------\n# 7. Hyperparameter Tuning\n# ------------------------------------------------------------\nnn_res &lt;- tune_grid(\n  nn_wf,\n  resamples = folds,\n  grid = nn_grid,\n  metrics = metric_set(roc_auc, accuracy),\n  control = control_grid(save_pred = TRUE)\n)\n\n# Examine tuning results\ncollect_metrics(nn_res)\nshow_best(nn_res, metric = \"roc_auc\", n = 10)\n\n# ------------------------------------------------------------\n# 8. Finalize Workflow with Best Parameters\n# ------------------------------------------------------------\nbest_nn &lt;- select_best(nn_res, metric = \"roc_auc\")\nnn_final_wf &lt;- finalize_workflow(nn_wf, best_nn)\n\n# ------------------------------------------------------------\n# 9. Final Test-Set Evaluation (honest performance)\n# ------------------------------------------------------------\nnn_last &lt;- last_fit(\n  nn_final_wf,\n  split = split,\n  metrics = metric_set(roc_auc, accuracy, sens, spec)\n)\n\ncollect_metrics(nn_last)\n\nnn_test_preds &lt;- collect_predictions(nn_last)\n\n# ROC curve (uses the event class probability column dynamically)\nnn_test_preds %&gt;%\n  roc_curve(outcome, !!sym(prob_col)) %&gt;%\n  autoplot()\n\n# Optional: confusion matrix at 0.5 threshold (you can choose a better threshold later)\nnn_test_preds %&gt;%\n  mutate(\n    .pred_class = factor(\n      if_else(!!sym(prob_col) &gt;= 0.5, event_level, levels(train$outcome)[1]),\n      levels = levels(train$outcome)\n    )\n  ) %&gt;%\n  conf_mat(outcome, .pred_class)\n\n# ------------------------------------------------------------\n# 10. Fit Final Model on Training Data (for interpretation/usage)\n# ------------------------------------------------------------\nnn_fit &lt;- fit(nn_final_wf, data = train)\n\n# Inspect finalized model specification\nextract_spec_parsnip(nn_fit)"
  },
  {
    "objectID": "tidymodels_overview.html#a.-objective-prediction-task-always-first",
    "href": "tidymodels_overview.html#a.-objective-prediction-task-always-first",
    "title": "Overview of tidymodels",
    "section": "A. Objective & prediction task (always first)",
    "text": "A. Objective & prediction task (always first)\nAnswer:\nWhat problem is the model solving?\nInclude: - Outcome definition - Population - Prediction vs explanation - Unit of prediction (patient, visit, image, etc.)\nExample:\n‚ÄúWe developed a machine learning model to predict 30-day mortality among hospitalized patients using routinely collected clinical variables.‚Äù\nüö´ Don‚Äôt start with algorithms. Start with the problem."
  },
  {
    "objectID": "tidymodels_overview.html#b.-data-study-design",
    "href": "tidymodels_overview.html#b.-data-study-design",
    "title": "Overview of tidymodels",
    "section": "B. Data & study design",
    "text": "B. Data & study design\nAnswer:\nWhere did the data come from, and how were they used?\nInclude: - Sample size - Outcome prevalence - Train/test split - Cross-validation strategy - Any stratification or grouping\nExample:\n‚ÄúThe dataset consisted of 4,812 patients, of whom 9.6% experienced the outcome. Data were split into training (80%) and test (20%) sets, stratified by outcome. Hyperparameters were optimized using 5-fold cross-validation on the training data.‚Äù\nThis signals methodological literacy."
  },
  {
    "objectID": "tidymodels_overview.html#c.-preprocessing-this-matters-more-than-people-think",
    "href": "tidymodels_overview.html#c.-preprocessing-this-matters-more-than-people-think",
    "title": "Overview of tidymodels",
    "section": "C. Preprocessing (this matters more than people think)",
    "text": "C. Preprocessing (this matters more than people think)\nAnswer:\nHow was the data prepared, and was leakage avoided?\nInclude: - Handling of categorical variables - Scaling (if applicable) - Missingness handling - Zero-variance filtering - Where preprocessing occurred (inside CV!)\nExample:\n‚ÄúCategorical predictors were dummy-encoded, and predictors with zero variance were removed using a recipe-based preprocessing pipeline. All preprocessing steps were estimated within resampling folds to prevent information leakage.‚Äù\nThat last sentence is very important!"
  },
  {
    "objectID": "tidymodels_overview.html#d.-model-specification-tuning",
    "href": "tidymodels_overview.html#d.-model-specification-tuning",
    "title": "Overview of tidymodels",
    "section": "D. Model specification & tuning",
    "text": "D. Model specification & tuning\nAnswer:\nWhat model was fit, and how were hyperparameters chosen?\nInclude: - Algorithm - Engine/library - Tuned parameters - Optimization metric\nRandom forest example:\n‚ÄúA random forest classifier was implemented using the ranger engine. The number of candidate predictors at each split (mtry) and the minimum node size (min_n) were optimized via grid search, selecting hyperparameters that maximized cross-validated ROC AUC.‚Äù\nüö´ Don‚Äôt just say ‚Äúwe fit a random forest.‚Äù"
  },
  {
    "objectID": "tidymodels_overview.html#e.-performance-evaluation-this-is-the-core",
    "href": "tidymodels_overview.html#e.-performance-evaluation-this-is-the-core",
    "title": "Overview of tidymodels",
    "section": "E. Performance evaluation (this is the core)",
    "text": "E. Performance evaluation (this is the core)\nAnswer:\nHow well does the model perform on unseen data?\nAlways include: - Held-out test set results - Primary metric - Secondary metrics - Confidence intervals if possible\nExample:\n‚ÄúOn the held-out test set, the model achieved an ROC AUC of 0.82, with sensitivity of 0.74 and specificity of 0.79 at a probability threshold of 0.5.‚Äù\nOptional (but impressive): - Calibration - Decision curves - Class imbalance handling"
  },
  {
    "objectID": "tidymodels_overview.html#f.-model-interpretation-with-restraint",
    "href": "tidymodels_overview.html#f.-model-interpretation-with-restraint",
    "title": "Overview of tidymodels",
    "section": "F. Model interpretation (with restraint)",
    "text": "F. Model interpretation (with restraint)\nAnswer:\nHow does the model behave, and what drives predictions?\nInclude: - Variable importance (with caveats) - Partial dependence / ALE / SHAP (if used) - Clear disclaimer about causality\nExample:\n‚ÄúPermutation-based variable importance indicated that age, baseline creatinine, and oxygen saturation contributed most strongly to predictive performance. Partial dependence plots suggested nonlinear risk increases at advanced ages; however, these plots reflect model behavior rather than causal effects.‚Äù\nThis shows statistical maturity."
  },
  {
    "objectID": "tidymodels_overview.html#g.-limitations-this-builds-trust",
    "href": "tidymodels_overview.html#g.-limitations-this-builds-trust",
    "title": "Overview of tidymodels",
    "section": "G. Limitations (this builds trust)",
    "text": "G. Limitations (this builds trust)\nAnswer:\nWhat could go wrong or limit generalization?\nAlways include: - Observational data limitations - External validation status - Model interpretability limits\nExample:\n‚ÄúThis analysis used retrospective single-source data, and external validation was not performed. Variable importance reflects predictive contribution rather than causal relevance.‚Äù\nReviewers expect this."
  },
  {
    "objectID": "tidymodels_overview.html#h.-practical-implications-next-steps",
    "href": "tidymodels_overview.html#h.-practical-implications-next-steps",
    "title": "Overview of tidymodels",
    "section": "H. Practical implications / next steps",
    "text": "H. Practical implications / next steps\nAnswer:\nWhat would you do next if this mattered?\nExample:\n‚ÄúFuture work includes external validation, calibration assessment, and comparison with simpler baseline models prior to potential deployment.‚Äù\nThis signals real-world thinking."
  }
]